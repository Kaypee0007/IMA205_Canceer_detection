{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "\n",
    "#### Importations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from skimage.io import imread\n",
    "from skimage.io import imsave\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "from skimage.transform import rotate\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import AxesGrid\n",
    "from time import time \n",
    "from scipy.ndimage.measurements import center_of_mass\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy import ndimage\n",
    "from skimage.morphology import binary_opening\n",
    "import cv2\n",
    "from skimage.color import rgb2hsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Réduction de taille\n",
    "Pour diminuer le temps de calcul des algorithmes, on réduit la taille des images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthis/anaconda3/lib/python3.6/site-packages/skimage/util/dtype.py:122: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n",
      "/Users/matthis/anaconda3/lib/python3.6/site-packages/skimage/io/_io.py:132: UserWarning: im_resized/IM_000720_Segmentation_resized.jpg is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps de calcul :  311.83210706710815\n"
     ]
    }
   ],
   "source": [
    "### On change la taille des Images####\n",
    "import cv2\n",
    "t = time()\n",
    "feat_df = pd.read_csv('features.csv', sep=';')\n",
    "\n",
    "# On parcourt toutes les images du dossier\n",
    "for x in feat_df['ImageId'].values:\n",
    "    filename = 'im/{}.jpg'.format(x)\n",
    "    filename_S = 'im/{}_Segmentation.jpg'.format(x)\n",
    "    # Chargement des images\n",
    "    image = imread(filename)\n",
    "    image_S = imread(filename_S, as_grey = True)\n",
    "    (h,w,d) = image.shape\n",
    "    # On veut que l'image garde la même forme, on fixe donc la largeur ou la longueur, selon les cas et on modifie \n",
    "    # proportionelement l'autre dimension\n",
    "    if w>d:\n",
    "        new_h, new_w = 300,int(w/h*300)\n",
    "    else :\n",
    "        new_w, new_h = 300,int(h/w*300)\n",
    "    # on applique le changement de taille et on l'enregistre\n",
    "    image_downsampled = resize(image,(new_h, new_w), mode='reflect')\n",
    "    image_Segmentation_downsampled = resize(image_S,(new_h, new_w), mode='reflect')\n",
    "    imsave('im_resized/{}_Segmentation_resized.jpg'.format(x), image_Segmentation_downsampled)\n",
    "    imsave('im_resized/{}_resized.jpg'.format(x), image_downsampled)\n",
    "    \n",
    "print('Temps de calcul : ', time()-t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La première erreur soulevée est due à la commande \"int(h/w*300)\" mais cela est nécéssaire car les coordonées de l'image ne peuvent pas être des réels. La seconde erreur vient du fait que la segmentation de l'image 720 est entièrement blanche, c'est à dire sans aucun contraste\n",
    "\n",
    "#### Asymétrie des formes\n",
    "\n",
    "Correspond au Paragraphe 2.3.1 de l'article https://www.sciencedirect.com/science/article/pii/S0933365713001589"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image:  50 , Temps :  98.58412289619446\n",
      "Image:  100 , Temps :  199.68367075920105\n",
      "Image:  150 , Temps :  296.52192187309265\n",
      "Image:  200 , Temps :  391.15829586982727\n",
      "Image:  250 , Temps :  483.26485300064087\n",
      "Image:  300 , Temps :  581.7804698944092\n",
      "Image:  350 , Temps :  671.7664840221405\n",
      "Image:  400 , Temps :  764.7944917678833\n",
      "Image:  450 , Temps :  858.178827047348\n",
      "Image:  500 , Temps :  952.8784098625183\n",
      "Image:  550 , Temps :  1046.7902228832245\n",
      "Image:  600 , Temps :  1140.2107746601105\n",
      "Image:  650 , Temps :  1228.828293800354\n",
      "Image:  700 , Temps :  1319.4477019309998\n",
      "Image:  750 , Temps :  1416.4046227931976\n",
      "Image:  800 , Temps :  1514.776107788086\n",
      "Image:  850 , Temps :  1609.883752822876\n",
      "Image:  900 , Temps :  1701.6312539577484\n",
      "1701.642431974411\n"
     ]
    }
   ],
   "source": [
    "#on calcule le temps car l'exécution est très longue\n",
    "t = time()\n",
    "# Toutes les 50 itérations de m, on va afficher l'avancée de l'algorithme\n",
    "m=0\n",
    "for x in feat_df['ImageId'].values:\n",
    "    m+=1\n",
    "    filename = 'im_resized/{}_resized.jpg'.format(x)\n",
    "    filename_S = 'im_resized/{}_Segmentation_resized.jpg'.format(x)\n",
    "    image = imread(filename)\n",
    "    image_S = imread(filename_S)\n",
    "    # Je seuille l'image car lors de l'enregistrement de la segmentation dans un fichier JPEG, puis la relecture,\n",
    "    # il y a des valeurs légèrement supérieur à 0. Or, on veut une image binaire. Cela n'est pas du à l'interpolation\n",
    "    # lors du sous-echantillonage.\n",
    "    ret, image_S = cv2.threshold(image_S, 177, 255, cv2.THRESH_BINARY)\n",
    "    image_S = image_S.astype(bool)\n",
    "        \n",
    "    # On convertit l'image en niveau de gris\n",
    "    gray_image = rgb2gray(image)*255\n",
    "    gray_image = np.array(gray_image, np.int32)\n",
    "    n,p = gray_image.shape\n",
    "    \n",
    "    # On calcule le centre de masse du masque de l'image.\n",
    "    i_center, j_center = center_of_mass(image_S)\n",
    "    i_center = int(i_center)\n",
    "    j_center = int(j_center)\n",
    "    #toutes les valeurs hors de la lésion doivent être nulles\n",
    "    masked_im = np.array(gray_image*image_S, np.int32)\n",
    "    # On cherche les valeurs minimales de DS1 et DS2 pour tous les axes orthogonaux \n",
    "    # tournés par pas de 10 degrés    \n",
    "    #on choisit des valeurs arbitrairement très grandes pour être sûr qu'un angle ait des valeur plus petites pour DS1 et DS2\n",
    "    averageDS = 100\n",
    "        \n",
    "    #on recentre et agrandie l'image pour que la lésion soit toujours dans l'image lors des rotations\n",
    "    padX = [p - j_center, j_center]\n",
    "    padY = [n - i_center, i_center]\n",
    "    imgP = np.pad(masked_im, [padY, padX], 'constant')\n",
    "        \n",
    "    for angle in [10*k for k in range(18)]:        \n",
    "        #rotated_image = rotate(masked_im, angle, center=(j_center, i_center))\n",
    "        rotated_image = ndimage.rotate(imgP, angle, output=np.int32 ,reshape=False)\n",
    "        #on ne veut pas que les valeur de l'image dépassent 0 ou 255\n",
    "        rotated_image = np.clip(rotated_image, 0, 255)\n",
    "            \n",
    "        nbis, pbis = rotated_image.shape\n",
    "            \n",
    "        # on calcule les différences des parties de la lésion \n",
    "        DS1 = np.sum(np.abs(rotated_image[:,:pbis//2]-np.fliplr(rotated_image[:,pbis//2:pbis])))\n",
    "        DS2 = np.sum(np.abs(rotated_image[:nbis//2,:]-np.flipud(rotated_image[nbis//2:nbis, :])))\n",
    "        \n",
    "        #On normalise les valeurs selon la taille du masque\n",
    "        DS1 /= np.sum(np.sum(image_S*255))\n",
    "        DS2 /= np.sum(np.sum(image_S*255))\n",
    "        #on choisit la combinaison qui minimise la moyenne des deux\n",
    "        if((DS1+DS2)/2 < averageDS):\n",
    "            minDS1 = DS1\n",
    "            minDS2 = DS2\n",
    "            averageDS = (DS1+DS2)/2\n",
    "        \n",
    "    if(m%50 ==0):\n",
    "        print(\"Image: \", m, \", Temps : \", time()-t)\n",
    "    feat_df.loc[feat_df['ImageId'] == x, 'f1'] = minDS1\n",
    "    feat_df.loc[feat_df['ImageId'] == x, 'f2'] = minDS2\n",
    "print(time()-t)\n",
    "feat_df.to_csv('features.csv', index=None, sep=';', mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Asymétrie des couleurs\n",
    "\n",
    "Correspond au Paragraphe 2.3.2 de l'article https://www.sciencedirect.com/science/article/pii/S0933365713001589"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image:  50 , Temps :  392.6701691150665\n",
      "Image:  100 , Temps :  848.6166729927063\n",
      "Image:  150 , Temps :  1283.4140889644623\n",
      "Image:  200 , Temps :  1729.4835178852081\n",
      "Image:  250 , Temps :  2115.733841896057\n",
      "Image:  300 , Temps :  2550.153974056244\n",
      "Image:  350 , Temps :  3000.3810329437256\n",
      "Image:  400 , Temps :  3446.1576159000397\n",
      "Image:  450 , Temps :  3919.5309607982635\n",
      "Image:  500 , Temps :  4379.600751876831\n",
      "Image:  550 , Temps :  4822.993721008301\n",
      "Image:  600 , Temps :  5213.594225883484\n",
      "Image:  650 , Temps :  5690.094100952148\n",
      "Image:  700 , Temps :  6073.771212100983\n",
      "Image:  750 , Temps :  6488.5040719509125\n",
      "Image:  800 , Temps :  6928.637995958328\n",
      "Image:  850 , Temps :  7332.421272039413\n",
      "Image:  900 , Temps :  7766.310403108597\n",
      "7766.364050865173\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "m=0\n",
    "for x in feat_df['ImageId'].values:\n",
    "    m+=1\n",
    "    filename = 'im_resized/{}_resized.jpg'.format(x)\n",
    "    filename_S = 'im_resized/{}_Segmentation_resized.jpg'.format(x)\n",
    "    image = imread(filename)\n",
    "    image_S = imread(filename_S)\n",
    "    ret, image_S = cv2.threshold(image_S, 177, 255, cv2.THRESH_BINARY)\n",
    "    image_S = image_S.astype(bool)\n",
    "    \n",
    "    #On convertit l'image en niveau de gris\n",
    "    gray_image = np.array(rgb2gray(image)*255, dtype = np.int32)\n",
    "    n,p = gray_image.shape\n",
    "    \n",
    "    #On calcule le centre de masse du masque de l'image.\n",
    "    i_center, j_center = center_of_mass(image_S)\n",
    "    i_center, j_center = int(i_center), int(j_center)\n",
    "    averageDC = 100\n",
    "    \n",
    "    #on applique le masque de segmentation à l'image\n",
    "    masked_im = gray_image * image_S\n",
    "    \n",
    "    #on recentre et agrandie l'image pour que la lésion soit toujours dans l'image lors des rotations\n",
    "    padX = [p - j_center, j_center]\n",
    "    padY = [n - i_center, i_center]\n",
    "    imgP = np.pad(masked_im, [padY, padX], 'constant')\n",
    "    \n",
    "    #on tourne de 0 à 170 degrés\n",
    "    for angle in [10*k for k in range(18)]:\n",
    "        # rotation de l'image\n",
    "        rotated_image = ndimage.rotate(imgP, angle, reshape=False)\n",
    "        \n",
    "        nbis, pbis = rotated_image.shape\n",
    "        \n",
    "        # on séléctionnes les quatres quarts de l'image\n",
    "        values_above_j = rotated_image[:, :pbis//2]\n",
    "        values_under_j = rotated_image[:, pbis//2:pbis]\n",
    "        \n",
    "        values_above_i = rotated_image[:nbis//2, :]\n",
    "        values_under_i = rotated_image[nbis//2:nbis, :]\n",
    "        \n",
    "        \n",
    "        #On enlève les valeurs nulles càd celles qui sont hors du masque et on met tout dans une seule liste\n",
    "        values_above_j = values_above_j[values_above_j > 0]\n",
    "        values_under_j = values_under_j[values_under_j > 0]\n",
    "        values_above_i = values_above_i[values_above_i > 0]\n",
    "        values_under_i = values_under_i[values_under_i > 0]\n",
    "        \n",
    "        # On calcule la distribution des ensembles\n",
    "        distribution_a_j = gaussian_kde(values_above_j)\n",
    "        distribution_u_j = gaussian_kde(values_under_j)\n",
    "        \n",
    "        distribution_a_i = gaussian_kde(values_above_i)\n",
    "        distribution_u_i = gaussian_kde(values_under_i)\n",
    "        \n",
    "        \n",
    "        A = np.linspace(0,255, 256)\n",
    "        # On calcule pour chaque valeur possible de pixel la différence de la distribution des différentes parties\n",
    "        DC1 = np.sum(np.abs(distribution_a_j(A) - distribution_u_j(A)))\n",
    "        DC2 = np.sum(np.abs(distribution_a_i(A) - distribution_u_i(A)))\n",
    "        \n",
    "        #On normalise les valeurs selon la taille du masque\n",
    "        DC1 /= np.sum(np.sum(image_S))\n",
    "        DC2 /= np.sum(np.sum(image_S))\n",
    "        \n",
    "        #on choisit la combinaison qui minimise la moyenne des deux\n",
    "        if((DC1+DC2)/2 < averageDC):\n",
    "            minDC1 = DC1\n",
    "            minDC2 = DC2\n",
    "            averageDC = (DC1+DC2)/2\n",
    "            \n",
    "    if(m%50 ==0):\n",
    "        print(\"Image: \", m, \", Temps : \", time()-t)\n",
    "    feat_df.loc[feat_df['ImageId'] == x, 'f3'] = minDC1\n",
    "    feat_df.loc[feat_df['ImageId'] == x, 'f4'] = minDC2\n",
    "\n",
    "feat_df.to_csv('features.csv', index=None, sep=';', mode='w')    \n",
    "print(time()-t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Asymétrie couleur - forme\n",
    "\n",
    "Correspond au Paragraphe 2.3.3 de l'article https://www.sciencedirect.com/science/article/pii/S0933365713001589"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image:  50 , Temps :  1.7509431838989258\n",
      "Image:  100 , Temps :  3.9118881225585938\n",
      "Image:  150 , Temps :  5.611047983169556\n",
      "Image:  200 , Temps :  7.484312057495117\n",
      "Image:  250 , Temps :  9.32894492149353\n",
      "Image:  300 , Temps :  11.174020290374756\n",
      "Image:  350 , Temps :  12.848567247390747\n",
      "Image:  400 , Temps :  14.647001266479492\n",
      "Image:  450 , Temps :  16.417936325073242\n",
      "Image:  500 , Temps :  18.09332823753357\n",
      "Image:  550 , Temps :  19.992983102798462\n",
      "Image:  600 , Temps :  22.17376208305359\n",
      "Image:  650 , Temps :  23.83597707748413\n",
      "Image:  700 , Temps :  25.27400016784668\n",
      "Image:  750 , Temps :  26.73813509941101\n",
      "Image:  800 , Temps :  28.269097089767456\n",
      "Image:  850 , Temps :  29.847776174545288\n",
      "Image:  900 , Temps :  31.42053198814392\n",
      "31.463662147521973\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "k=0\n",
    "for x in feat_df['ImageId'].values:\n",
    "    k+=1\n",
    "    filename = 'im_resized/{}_resized.jpg'.format(x)\n",
    "    filename_S = 'im_resized/{}_Segmentation_resized.jpg'.format(x)\n",
    "    image = imread(filename)\n",
    "    image_S = imread(filename_S)\n",
    "    ret, image_S = cv2.threshold(image_S, 178, 255, cv2.THRESH_BINARY)     \n",
    "    mask = image_S.astype(bool)\n",
    "    #On convertit l'image en niveau de gris\n",
    "    gray_image = np.array(rgb2gray(image)*255, np.int32)\n",
    "    n,p = gray_image.shape\n",
    "\n",
    "    #On calcule le centre de masse du masque de l'image.\n",
    "    i_center, j_center = center_of_mass(image_S)\n",
    "    i_center, j_center = np.int(i_center), np.int(j_center)\n",
    "    # on enlève toutes les valeurs nulles car ce sont celles en dehors de la lesion\n",
    "    lesion_values = gray_image*mask\n",
    "    lesion_values = lesion_values[lesion_values>0]\n",
    "    \n",
    "    percentiles = np.percentile(lesion_values, np.linspace(10, 90, 9), interpolation = 'lower')\n",
    "    #contient les ditances euclidiennes entres les nouveaux centres de masse\n",
    "    v=[]\n",
    "    for per in percentiles:\n",
    "\n",
    "        #centre de masse du masque des valeurs superieur au percentile per\n",
    "        new_i, new_j = center_of_mass(gray_image*mask > per)\n",
    "        #on ajoute la ditance eucliedienne\n",
    "        v.append(np.sqrt((i_center-new_i)**2+(j_center-new_j)**2))\n",
    "\n",
    "    # on normalise v par le rayon d'un cerlce d'aire égale à celle de la segmentation Image_S\n",
    "    v = v/(np.sqrt(sum(sum(image_S))/np.pi))\n",
    "\n",
    "    feat_df.loc[feat_df['ImageId'] == x, 'f5'] = np.mean(v)\n",
    "    feat_df.loc[feat_df['ImageId'] == x, 'f6'] = np.std(v)\n",
    "\n",
    "    if(k%50==0):\n",
    "        print(\"Image: \", k, \", Temps : \", time()-t)\n",
    "\n",
    "feat_df.to_csv('features.csv', index=None, sep=';', mode='w')    \n",
    "print(time()-t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Geométrie\n",
    "\n",
    "Correspond au Paragraphe 2.3.8 de l'article https://www.sciencedirect.com/science/article/pii/S0933365713001589"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image:  50 , Temps :  1.7220351696014404\n",
      "Image:  100 , Temps :  3.2678439617156982\n",
      "Image:  150 , Temps :  5.051492929458618\n",
      "Image:  200 , Temps :  6.717071056365967\n",
      "Image:  250 , Temps :  8.248589038848877\n",
      "Image:  300 , Temps :  10.21944785118103\n",
      "Image:  350 , Temps :  11.780915975570679\n",
      "Image:  400 , Temps :  13.415989875793457\n",
      "Image:  450 , Temps :  15.025693893432617\n",
      "Image:  500 , Temps :  16.51211905479431\n",
      "Image:  550 , Temps :  17.977150917053223\n",
      "Image:  600 , Temps :  19.44136381149292\n",
      "Image:  650 , Temps :  21.09029793739319\n",
      "Image:  700 , Temps :  22.54696488380432\n",
      "Image:  750 , Temps :  24.018200874328613\n",
      "Image:  800 , Temps :  25.489809036254883\n",
      "Image:  850 , Temps :  26.96040391921997\n",
      "Image:  900 , Temps :  28.42581009864807\n",
      "28.49964213371277\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "k=1\n",
    "for x in feat_df['ImageId'].values:\n",
    "    filename = 'im_resized/{}_resized.jpg'.format(x)\n",
    "    filename_S = 'im_resized/{}_Segmentation_resized.jpg'.format(x)\n",
    "    image = imread(filename)\n",
    "    image_S = imread(filename_S)       \n",
    "    ret, image_S = cv2.threshold(image_S, 178, 255, cv2.THRESH_BINARY)          \n",
    "    image_S = image_S.astype(bool)\n",
    "    n,p,d = image.shape\n",
    "    \n",
    "    #on met toutes les valeurs hors du masque à 0\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    masked_gray_image = gray_image*image_S\n",
    "        \n",
    "    #on choisit les valeurs non nulles car il s'agit de celles qui sont dans le masque (la lésion)\n",
    "    im_values = masked_gray_image[masked_gray_image>0]\n",
    "    \n",
    "    #on calcule les quantiles à 0.25, 0.5 et 0.75\n",
    "    percentiles = np.percentile(im_values, [25, 50, 75], interpolation='lower')\n",
    "    \n",
    "    #liste qui contient le nombre de composantes connexes\n",
    "    num_conx = []\n",
    "    for per in percentiles:\n",
    "        ret, thresh = cv2.threshold(masked_gray_image, per, 255, cv2.THRESH_BINARY)\n",
    "        #on applique une ouverture au masque des valeurs inférieures au percentile donné\n",
    "        im_p1 = binary_opening(255 - thresh, [[0,1,0], [1,1,1], [0,1,0]])\n",
    "        im_p1 = im_p1*image_S\n",
    "        im_p1 = np.uint8(im_p1)\n",
    "        #on cherche les composantes connexes\n",
    "        output = cv2.connectedComponents(im_p1, 8)\n",
    "        #on ajoute le nombre de composantes connexes\n",
    "        num_conx.append(output[0]-1)\n",
    "    \n",
    "    feat_df.loc[feat_df['ImageId'] == x, 'f15'] = num_conx[0]\n",
    "    feat_df.loc[feat_df['ImageId'] == x, 'f16'] = num_conx[1]\n",
    "    feat_df.loc[feat_df['ImageId'] == x, 'f17'] = num_conx[2]\n",
    "    k+=1\n",
    "    if(k%50 == 0):\n",
    "        print(\"Image: \", k, \", Temps : \", time()-t)\n",
    "        \n",
    "feat_df.to_csv('features.csv', index=None, sep=';', mode='w')    \n",
    "print(time()-t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Moyenne, variance, 5e percentile et 95e percentile en HSV\n",
    "D'après :  https://ieeexplore.ieee.org/document/918473/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temps d'execution : 77.58569693565369 secondes\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "for x in feat_df['ImageId'].values:\n",
    "    filename = 'im_resized/{}_resized.jpg'.format(x)\n",
    "    filename_S = 'im_resized/{}_Segmentation_resized.jpg'.format(x)\n",
    "    image = imread(filename)\n",
    "    image_S = imread(filename_S)\n",
    "    ret, image_Segmentation_downsampled = cv2.threshold(image_Segmentation_downsampled, 178, 255, cv2.THRESH_BINARY)          \n",
    "    mask = image_S.astype(bool)\n",
    "    n,p,d = image.shape\n",
    "    \n",
    "    #on convertit l'image dans le domaine HSV\n",
    "    image = rgb2hsv(image)\n",
    "    # on normalise les images\n",
    "    unique, count = np.unique(image[:,:,0], return_counts= True)\n",
    "    h_image = image[:,:,0] - unique[np.argmax(count)]\n",
    "    #on sélectionne les valeurs hors du masque (la peau qui n'est pas la lésion)\n",
    "    out_skin = image[:,:,2]*(1-mask)\n",
    "    out_skin = out_skin[out_skin>0]\n",
    "    v_image = image[:,:,2]-np.mean(out_skin)\n",
    "    #les valeurs nulles sont celles qui sont hors du masque donc on les enlève\n",
    "    v_lesion_values = v_image[v_image*mask !=0]\n",
    "    h_lesion_values = h_image[h_image*mask !=0]\n",
    "    \n",
    "    feat_df.loc[feat_df['ImageId'] == x, 'f7'] = np.percentile(v_lesion_values, 5, interpolation = 'lower')\n",
    "    feat_df.loc[feat_df['ImageId'] == x, 'f8'] = np.percentile(v_lesion_values, 95, interpolation = 'lower')\n",
    "    feat_df.loc[feat_df['ImageId'] == x, 'f9'] = np.mean(v_lesion_values)\n",
    "    feat_df.loc[feat_df['ImageId'] == x, 'f10'] = np.var(v_lesion_values)\n",
    "    \n",
    "    feat_df.loc[feat_df['ImageId'] == x, 'f11'] = np.percentile(h_lesion_values, 5, interpolation = 'lower')\n",
    "    feat_df.loc[feat_df['ImageId'] == x, 'f12'] = np.percentile(h_lesion_values, 95, interpolation = 'lower')\n",
    "    feat_df.loc[feat_df['ImageId'] == x, 'f13'] = np.mean(h_lesion_values)\n",
    "    feat_df.loc[feat_df['ImageId'] == x, 'f14'] = np.var(h_lesion_values)\n",
    "\n",
    "feat_df.to_csv('features.csv', index=None, sep=';', mode='w')\n",
    "print(\"temps d'execution :\", time()-t, \"secondes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Moyenne, variance, percentiles de RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temps d'execution : 58.56622505187988 secondes\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "for x in feat_df['ImageId'].values:\n",
    "    filename = 'im_resized/{}_resized.jpg'.format(x)\n",
    "    filename_S = 'im_resized/{}_Segmentation_resized.jpg'.format(x)\n",
    "    image = imread(filename)\n",
    "    image_S = imread(filename_S)\n",
    "    ret, image_Segmentation_downsampled = cv2.threshold(image_Segmentation_downsampled, 178, 255, cv2.THRESH_BINARY)          \n",
    "    mask = image_S.astype(bool)\n",
    "    n,p,d = image.shape\n",
    "    \n",
    "    r_lesion_values = image[:,:,0][image[:,:,0]*mask !=0]/255\n",
    "    g_lesion_values = image[:,:,1][image[:,:,1]*mask !=0]/255\n",
    "    b_lesion_values = image[:,:,2][image[:,:,2]*mask !=0]/255\n",
    "    \n",
    "    feat_df.loc[feat_df['ImageId'] == x, 'f18'] = np.percentile(r_lesion_values, 5, interpolation = 'lower')\n",
    "    feat_df.loc[feat_df['ImageId'] == x, 'f19'] = np.percentile(r_lesion_values, 95, interpolation = 'lower')\n",
    "    feat_df.loc[feat_df['ImageId'] == x, 'f20'] = np.mean(r_lesion_values)\n",
    "    feat_df.loc[feat_df['ImageId'] == x, 'f21'] = np.var(r_lesion_values)\n",
    "    \n",
    "    feat_df.loc[feat_df['ImageId'] == x, 'f22'] = np.percentile(g_lesion_values, 5, interpolation = 'lower')\n",
    "    feat_df.loc[feat_df['ImageId'] == x, 'f23'] = np.percentile(g_lesion_values, 95, interpolation = 'lower')\n",
    "    feat_df.loc[feat_df['ImageId'] == x, 'f24'] = np.mean(g_lesion_values)\n",
    "    feat_df.loc[feat_df['ImageId'] == x, 'f25'] = np.var(g_lesion_values)\n",
    "    \n",
    "    feat_df.loc[feat_df['ImageId'] == x, 'f26'] = np.percentile(b_lesion_values, 5, interpolation = 'lower')\n",
    "    feat_df.loc[feat_df['ImageId'] == x, 'f27'] = np.percentile(b_lesion_values, 95, interpolation = 'lower')\n",
    "    feat_df.loc[feat_df['ImageId'] == x, 'f28'] = np.mean(b_lesion_values)\n",
    "    feat_df.loc[feat_df['ImageId'] == x, 'f29'] = np.var(b_lesion_values)\n",
    "feat_df.to_csv('features.csv', index=None, sep=';', mode='w')\n",
    "print(\"temps d'execution :\", time()-t, \"secondes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "#### Importations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import matthews_corrcoef \n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formation de l'ensemble d'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on importe les données\n",
    "df = pd.read_csv('train.csv')\n",
    "df_train_features = pd.merge(feat_df, df, on = 'ImageId')\n",
    "#on enlève la dernière colonne car il s'agit de la classification et la première car il s'agit des Identifiants\n",
    "X_train = df_train_features.iloc[:, 1:df_train_features.shape[1]-1]\n",
    "Y_train = df_train_features.Malignant.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On augmente les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm =SMOTE()\n",
    "X_train, Y_train = sm.fit_sample(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(970, 29)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scale = StandardScaler()\n",
    "X_train = scale.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise GridSearchCV pour choisir les meilleurs paramètres possibles. On va répéter l'opération pour différents classifieur et regarder lequel donne le meilleur score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "Score :  0.821419398242\n"
     ]
    }
   ],
   "source": [
    "grid_svc = [{'kernel': ['rbf'], 'gamma': [1e-1, 1e-2,1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "#on choisit le coefficient de corrélation de matthews en tant que score\n",
    "estimator = GridSearchCV(SVC(), grid_svc, scoring = make_scorer(matthews_corrcoef))\n",
    "estimator.fit(X_train, Y_train)\n",
    "print(estimator.best_params_)\n",
    "print(\"Score : \", estimator.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 29, 'n_estimators': 50}\n",
      "Score :  0.765829196\n"
     ]
    }
   ],
   "source": [
    "grid_RDF = {'max_depth': [10, 20, 25, 29], 'n_estimators': [20,30, 40, 50, 60, 70]}\n",
    "            \n",
    "#on choisit le coefficient de corrélation de matthews en tant que score\n",
    "estimator = GridSearchCV(RandomForestClassifier(), grid_RDF, scoring = make_scorer(matthews_corrcoef))\n",
    "estimator.fit(X_train, Y_train)\n",
    "print(estimator.best_params_)\n",
    "print(\"Score : \",estimator.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 10}\n",
      "Score :  0.609455596214\n"
     ]
    }
   ],
   "source": [
    "grid_tree = {'max_depth': [10, 20, 25, 29]}\n",
    "\n",
    "#on choisit le coefficient de corrélation de matthews en tant que score\n",
    "estimator = GridSearchCV(DecisionTreeClassifier(), grid_tree, scoring = make_scorer(matthews_corrcoef))\n",
    "estimator.fit(X_train, Y_train)\n",
    "print(estimator.best_params_)\n",
    "print(\"Score : \",estimator.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score :  0.463459616852\n"
     ]
    }
   ],
   "source": [
    "grid_lda = {}\n",
    "\n",
    "#on choisit le coefficient de corrélation de matthews en tant que score\n",
    "estimator = GridSearchCV(LDA(), grid_lda, scoring = make_scorer(matthews_corrcoef))\n",
    "estimator.fit(X_train, Y_train)\n",
    "print(\"Score : \",estimator.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score :  0.536026074001\n"
     ]
    }
   ],
   "source": [
    "grid_qda = {}\n",
    "\n",
    "#on choisit le coefficient de corrélation de matthews en tant que score\n",
    "estimator = GridSearchCV(QDA(), grid_qda, scoring = make_scorer(matthews_corrcoef))\n",
    "estimator.fit(X_train, Y_train)\n",
    "print(\"Score : \",estimator.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C'est SVM avec un noyau gaussien, C = 100 et gamma = 0.1 qui semble être le meilleur classifieur car il obtient un score plus élevé que les autres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthis/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='rbf', C= 100, gamma=0.1)\n",
    "clf.fit(X_train, Y_train)\n",
    "# on ouvre le fichier où les identifiants des photos de test sont stockées\n",
    "df_submission = pd.read_csv('test.csv', sep=',')\n",
    "\n",
    "for Id in df_submission['ImageId']:\n",
    "    val = feat_df.loc[feat_df['ImageId'] == Id].values[0, 1:]\n",
    "    # il faut centrer et réduire les données de test aussi\n",
    "    df_submission.loc[df_submission['ImageId'] == Id, 'Malignant'] = clf.predict(scale.transform(np.array([val])))\n",
    "    \n",
    "df_submission['Malignant'] = df_submission['Malignant'].astype(int)\n",
    "# on enregistre la prédiction\n",
    "df_submission.to_csv('test.csv', index=None, sep=',', mode='w') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On obtient un score de 0.23431"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pca__n_components': 23, 'svc__C': 100, 'svc__gamma': 0.1}\n",
      "0.821515933873\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline(steps=[('pca', PCA()), ('svc', SVC(kernel ='rbf'))])\n",
    "estimator = GridSearchCV(pipe, dict(pca__n_components = [21,22,23,24,25,26,27,28, 29], svc__C = [100], svc__gamma=[0.1]), scoring = make_scorer(matthews_corrcoef))\n",
    "estimator.fit(X_train, Y_train)\n",
    "\n",
    "print(estimator.best_params_)\n",
    "print(estimator.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'erreur est quasiment la même qu'avec 29 features. De plus, lorsque l'on fait la prediction avec l'estimateur calculé, on obtient exactement le même fichier que si l'on avait pas fait la PCA. On ne va donc pas appliquer la PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
