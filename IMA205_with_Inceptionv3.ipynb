{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce fichier, nous allons essayer de classifier les lésions en utilisant un réseau de neurones convolutif suivi d'une SVM.\n",
    "#### Importations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.python.platform\n",
    "from tensorflow.python.platform import gfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import matthews_corrcoef \n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from time import time\n",
    "from sklearn.ensemble import RandomForestClassifier as RDF\n",
    "import cv2\n",
    "from skimage.io import imread\n",
    "from skimage.io import imsave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps de calcul :  115.13847923278809\n"
     ]
    }
   ],
   "source": [
    "### On change la taille des Images####\n",
    "t = time()\n",
    "feat_df = pd.read_csv('features.csv', sep=';')\n",
    "\n",
    "# On parcours toutes les images du dossier\n",
    "for x in feat_df['ImageId'].values:\n",
    "    filename = 'im/{}.jpg'.format(x)\n",
    "    filename_S = 'im/{}_Segmentation.jpg'.format(x)\n",
    "    image = imread(filename)\n",
    "    image_S = imread(filename_S, as_grey = True)\n",
    "    #on applique le masque\n",
    "    image = cv2.bitwise_and(image, image, mask = image_S)\n",
    "    # on cahnge la taille        \n",
    "    seg_image = cv2.resize(image,(149,149))\n",
    "    imsave('im_resized2/{}_Segmentation_resized.jpg'.format(x), seg_image)\n",
    "    \n",
    "print('Temps de calcul : ', time()-t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonctions tirées de https://code.oursky.com/tensorflow-svm-image-classifications-engine/\n",
    "\n",
    "La première initialise le réseau et la deuxième calcule les features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_graph(model_path):\n",
    "    \"\"\"\n",
    "    create_graph loads the inception model to memory, should be called before\n",
    "    calling extract_features.\n",
    " \n",
    "    model_path: path to inception model in protobuf form.\n",
    "    \"\"\"\n",
    "    with gfile.FastGFile(model_path, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        _ = tf.import_graph_def(graph_def, name='')\n",
    " \n",
    " \n",
    "def extract_features(image_paths, verbose=False):\n",
    "    \"\"\"\n",
    "    extract_features computed the inception bottleneck feature for a list of images\n",
    " \n",
    "    image_paths: array of image path\n",
    "    return: 2-d array in the shape of (len(image_paths), 2048)\n",
    "    \"\"\"\n",
    "    feature_dimension = 2048\n",
    "    features = np.empty((len(image_paths), feature_dimension))\n",
    " \n",
    "    with tf.Session() as sess:\n",
    "        flattened_tensor = sess.graph.get_tensor_by_name('pool_3:0')\n",
    " \n",
    "        for i, image_path in enumerate(image_paths):\n",
    "            if verbose:\n",
    "                print('Processing %s...' % (image_path))\n",
    " \n",
    "            if not gfile.Exists(image_path):\n",
    "                tf.logging.fatal('File does not exist %s', image)\n",
    "            \n",
    "            #print(image_path)\n",
    "            if (i%100 == 0):\n",
    "                print(\"Processing image n° :\", i)\n",
    "            image_data = gfile.FastGFile(image_path, 'rb').read()\n",
    "            feature = sess.run(flattened_tensor, {\n",
    "                'DecodeJpeg/contents:0': image_data\n",
    "            })\n",
    "            features[i, :] = np.squeeze(feature)\n",
    " \n",
    "    return features \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image n° : 0\n",
      "Processing image n° : 100\n",
      "Processing image n° : 200\n",
      "Processing image n° : 300\n",
      "Processing image n° : 400\n",
      "Processing image n° : 500\n",
      "Processing image n° : 600\n",
      "Processing image n° : 700\n",
      "Processing image n° : 800\n",
      "(900, 2048)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('all.csv', sep=',')\n",
    "# all.csv contient les les identifiants de toutes les images. Les 300 premiers sont ceux du test set et \n",
    "# les 600 autres ceux du training set\n",
    "X_df = df['ImageId'].values\n",
    "\n",
    "# le nom de toutes les images qui vont être entrées dans le réseau\n",
    "images_dir = 'im_resized2/' + X_df + '_Segmentation_resized.jpg'\n",
    "create_graph('tensorflow_inception_graph.pb')\n",
    "features = extract_features(images_dir)\n",
    "\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv', sep=',')\n",
    "Y_train = df_train['Malignant'].values\n",
    "X_train = features[300:, :]\n",
    "X_test = features[:300, :]\n",
    "# on va centrer et réduire les données\n",
    "scale = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthis/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/matthis/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/matthis/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/matthis/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/matthis/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/matthis/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/matthis/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/matthis/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/matthis/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/matthis/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/matthis/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/matthis/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/matthis/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/matthis/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/matthis/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/matthis/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/matthis/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/matthis/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/matthis/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/matthis/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/matthis/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/matthis/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/matthis/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/matthis/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:538: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pca__n_components': 100, 'svc__C': 10, 'svc__gamma': 0.0001}\n",
      "Score :  0.338313212061\n"
     ]
    }
   ],
   "source": [
    "#on fait un pipeline pour trouver les meilleurs paramètres avec la pca\n",
    "pipe = Pipeline(steps=[('pca', PCA()), ('svc', SVC(kernel='rbf'))])\n",
    "\n",
    "estimator = GridSearchCV(pipe, dict(pca__n_components=[100, 500, 1000,2048], svc__C= [10, 100],\n",
    "                                    svc__gamma = [ 1e-2,1e-3, 1e-4]), scoring = make_scorer(matthews_corrcoef))\n",
    "estimator.fit(scale.fit_transform(X_train), Y_train)\n",
    "print(estimator.best_params_)\n",
    "print(\"Score : \", estimator.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On enregistre la prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test.csv', sep=',')\n",
    "df_test['Malignant'] = estimator.predict(scale.transform(X_test))\n",
    "df_test.to_csv('test.csv', index=None, sep=',', mode='w') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le score obtenu est de 0.37007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
